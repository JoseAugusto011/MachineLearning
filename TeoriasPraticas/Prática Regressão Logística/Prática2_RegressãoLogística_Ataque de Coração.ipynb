{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMu5kM00osuQIbirO6Wscd9"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"sKPfuEnapDnU"},"source":["# <font color=\"darkblue\"> Prática 02: Regressão Logística - Ataque de Coração</font>"]},{"cell_type":"markdown","metadata":{"id":"nKa5whanpntS"},"source":["**Objetivos:**\n","\n","\n","*   Apresentar  plataforma Kaglee\n","*   Inferir dados de uma base real utilizando o algoritmo de Regressão Logística \n","\n","**Requisitos de execução:**\n","\n","\n","*   Upload dos arquivos *logisticregression.py* e *heart_failure_clinical_records_dataset.csv*"]},{"cell_type":"markdown","metadata":{"id":"OPCbV-Udr1Pz"},"source":["**Atividade 1:**\n","\n","1. Visitar a base de dados: https://www.kaggle.com/andrewmvd/heart-failure-clinical-data\n","2. Carregar os dados do arquivo *heart_failure_clinical_records_dataset.csv* utilizando o pandas.\n","\n","    "]},{"cell_type":"code","metadata":{"id":"ZROjmwlFocyd"},"source":["import pandas as pd\n","import numpy as np\n","\n","heart_data = pd.read_csv('heart_failure_clinical_records_dataset.csv')\n","print(heart_data.head())\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"O73AMlZRtOTU"},"source":["**Atividade 2:**\n","\n","1. Extrair os valores do *DataFrame* pandas e colocar nas variáveis\n"]},{"cell_type":"code","metadata":{"id":"sU9ugDeOtaHd"},"source":["from sklearn.preprocessing import StandardScaler\n","\n","Features = ['time', 'anaemia','creatinine_phosphokinase','diabetes','ejection_fraction','serum_creatinine','age', 'high_blood_pressure', 'platelets', 'serum_sodium', 'sex', 'smoking']\n","\n","\n","sc = StandardScaler()\n","sc.fit(heart_data[Features].values)\n","\n","\n","x = sc.transform(heart_data[Features].values)\n","#x = heart_data[Features].values\n","y = heart_data[\"DEATH_EVENT\"].values\n","\n","print(\"d: \" + str(len(Features)))\n","print(\"N: \" + str(len(y)))\n","print(y)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LWlIeFootavy"},"source":["**Atividade 3:**\n","\n","1. Separar os dados em conjunto de treinamento e teste\n"]},{"cell_type":"code","metadata":{"id":"1CEvKox1tsWj"},"source":["from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","\n","x_T, x_test, y_T, y_test = train_test_split(x,y, test_size=0.25, random_state=0)\n","\n","#sc1 = StandardScaler()\n","#sc1.fit(x_T)\n","#x_test = sc1.transform(x_test)\n","#x_T = sc1.transform(x_T)\n","\n","print(\"Tamanho treinamento: \" + str(len(x_T)))\n","print(\"Tamanho teste: \" + str(len(x_test)))\n","\n","print(x_test)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gGjfXNZ-tsor"},"source":["**Atividade 4:**\n","\n","1. Inferir a função a função hipótese $g(x)=\\theta(w^Tx)$ dos dados de treinamento;\n","2. Computar o erro dentro da amostra ($E_{in}$);\n","3. Predizer os dados de teste usando $g(x)$;\n","4. Computar o erro fora da amostra ($E_{out}$);\n","5. Computar as métricas de aprendizado sobre o dados de teste.\n","6. Aplique a normalização dos dados de entrada e reexecute todos os experimentos. Compare os resultados."]},{"cell_type":"code","metadata":{"id":"jvw7C1Odt3Jb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679914591048,"user_tz":180,"elapsed":1895,"user":{"displayName":"Gilberto Farias","userId":"08659255523274913012"}},"outputId":"811343ee-3351-42e5-dc17-8b2d84998ec3"},"source":["from logisticregression import LogisticRegression\n","from sklearn.metrics import classification_report\n","\n","lrY = [+1 if value == 1 else -1 for value in y_T]\n","lrY_test = [+1 if value == 1 else -1 for value in y_test]\n","\n","#Regressão Logistica\n","classifier = LogisticRegression(0.1, 3000, 32)\n","classifier.fit(x_T, lrY)\n","\n","\n","#Computando o erro dentro da amostra (Ein)\n","N_in = len(lrY)\n","class_pred = classifier.predict(x_T)\n","eIn = 0\n","for i in range(N_in):\n","    if(class_pred[i] != lrY[i]):\n","        eIn += 1\n","eIn /= N_in\n","print(\"Ein = \" + str(eIn))\n","\n","#Computando o erro dentro da amostra (Eout)\n","N_out = len(lrY_test)\n","class_pred = classifier.predict(x_test)\n","eOut = 0\n","for i in range(N_out):\n","    if(class_pred[i] != lrY_test[i]):\n","        eOut += 1\n","eOut /= N_out\n","print(\"Eout = \" + str(eOut))\n","\n","\n","print(classification_report(lrY_test, class_pred))"],"execution_count":38,"outputs":[{"output_type":"stream","name":"stdout","text":["Ein = 0.13392857142857142\n","Eout = 0.22666666666666666\n","              precision    recall  f1-score   support\n","\n","          -1       0.77      0.92      0.84        48\n","           1       0.78      0.52      0.62        27\n","\n","    accuracy                           0.77        75\n","   macro avg       0.77      0.72      0.73        75\n","weighted avg       0.77      0.77      0.76        75\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"0SH_p2JeTmEN"},"source":["**Atividade 5:**\n","\n","1. Reproduza o mesmo experimento com a classe LogisticRegression do pacote *sklearn.metrics*"]},{"cell_type":"code","metadata":{"id":"GbnZN9PUQQ0d","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679914597716,"user_tz":180,"elapsed":313,"user":{"displayName":"Gilberto Farias","userId":"08659255523274913012"}},"outputId":"b26617a3-99ed-418a-a919-47c025eb7eb9"},"source":["from sklearn.metrics import classification_report\n","from sklearn.linear_model import LogisticRegression\n","\n","model = LogisticRegression()\n","model.fit(x_T, y_T)\n","\n","print(classification_report(y_test, model.predict(x_test)))"],"execution_count":39,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.77      0.92      0.84        48\n","           1       0.78      0.52      0.62        27\n","\n","    accuracy                           0.77        75\n","   macro avg       0.77      0.72      0.73        75\n","weighted avg       0.77      0.77      0.76        75\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"IA3iY7ZY_XdU"},"source":["**Atividade 6:**\n","\n","1. Exiba os parâmetros (Features) de $X$ ordenados pela sua importância na função de decisão, este valor é indicado pelo vetor $w$. No pacote sklearn.linear_model.LogisticRegression, utilize o atributo $coef_$."]},{"cell_type":"code","metadata":{"id":"7Eogo8_h_iYk"},"source":["param = [(np.exp(coef), f) for coef, f in zip(classifier.w, Features)]\n","param.sort(reverse=True)\n","for p in param:\n","  print(p)\n","\n","print(\"\")\n","param = [(np.exp(coef), f) for coef, f in zip(model.coef_[0], Features)]\n","param.sort(reverse=True)\n","\n","for p in param:\n","  print(p)"],"execution_count":null,"outputs":[]}]}